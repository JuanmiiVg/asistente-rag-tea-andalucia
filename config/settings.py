# config/settings.py

from pathlib import Path
import os
from dotenv import load_dotenv

BASE_DIR = Path(__file__).resolve().parent.parent

# Construimos la ruta exacta al archivo .env
dotenv_path = BASE_DIR / ".env"

# Cargamos las variables de entorno desde esa ruta expl√≠cita
if dotenv_path.exists():
    load_dotenv(dotenv_path=dotenv_path)
    print(f"‚úÖ Archivo .env encontrado y cargado desde: {dotenv_path}")
else:
    print(f"‚ùå ERROR: Archivo .env NO encontrado en la ruta esperada: {dotenv_path}")

api_key_value = os.getenv("GOOGLE_API_KEY")
if api_key_value:
    print(f"üîç Depuraci√≥n: La variable GOOGLE_API_KEY se ha cargado correctamente.")
else:
    print(f"üîç Depuraci√≥n: La variable GOOGLE_API_KEY es None. Revisa el archivo .env")


# --- Rutas del Proyecto ---
DATA_DIR = BASE_DIR / "data"
DATA_CLEAN_DIR = BASE_DIR / "data_clean"
CHUNKS_DIR = BASE_DIR / "chunks"
EMBEDDINGS_DIR = BASE_DIR / "embeddings"

# --- Configuraci√≥n de Modelos y APIs ---
# Modelo de embeddings de Hugging Face (multiling√ºe y ligero)
EMBEDDING_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# Configuraci√≥n de la API de Google Gemini
# Leemos la variable de entorno por su NOMBRE
GOOGLE_API_KEY = api_key_value
LLM_MODEL_NAME = "models/gemini-2.5-flash-lite" # o "gemini-1.5-pro" para m√°s calidad

# --- Configuraci√≥n de Chunking ---
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

# --- Configuraci√≥n de B√∫squeda (RAG) ---
TOP_K_CHUNKS = 4 # N√∫mero de fragmentos m√°s relevantes a recuperar

# --- Creaci√≥n de Directorios ---
# Asegurarse de que los directorios existan antes de empezar
for dir_path in [DATA_DIR, DATA_CLEAN_DIR, CHUNKS_DIR, EMBEDDINGS_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

print("‚úÖ Configuraci√≥n cargada y directorios verificados.")